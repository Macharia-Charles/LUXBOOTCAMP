{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import Adam\n",
    "from joblib import dump\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = './animals-detection-images-dataset/train'\n",
    "test_dir = \"./animals-detection-images-dataset/test\"\n",
    "categories = ['Bear', 'Brown bear', 'Bull', 'Butterfly', 'Camel', 'Canary', 'Caterpillar', 'Cattle', 'Centipede',\n",
    "              'Cheetah', 'Chicken', 'Crab', 'Crocodile', 'Deer', 'Duck', 'Eagle', 'Elephant', 'Fish', 'Fox',\n",
    "              'Frog', 'Giraffe', 'Goat', 'Goldfish', 'Goose', 'Hamster', 'Harbor Seal', 'Hedgehog', 'Hippopotamus',\n",
    "              'Horse', 'Jaguar', 'Jellyfish', 'Kangaroo', 'Koala', 'Ladybug', 'Leopard', 'Lion', 'Lizard',\n",
    "              'Lynx', 'Magpie', 'Monkey', 'Moths and butterflies', 'Mouse', 'Mule', 'Ostrich', 'Otter', 'Owl',\n",
    "              'Panda', 'Parrot', 'Penguin', 'Pig', 'Polar bear', 'Rabbit', 'Raccoon', 'Raven', 'Red panda',\n",
    "              'Rhinoceros', 'Scorpion', 'Sea lion', 'Sea turtle', 'Seahorse', 'Shark', 'Sheep', 'Shrimp',\n",
    "              'Snail', 'Snake', 'Sparrow', 'Spider', 'Squid', 'Squirrel', 'Starfish', 'Swan', 'Tick', 'Tiger',\n",
    "              'Tortoise', 'Turkey', 'Turtle', 'Whale', 'Woodpecker', 'Worm', 'Zebra']\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in categories: \n",
    "    category_path = os.path.join(train_dir, category)\n",
    "    for file in os.listdir(category_path):\n",
    "        img_path = os.path.join(category_path, file)\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        img = np.asarray(img)\n",
    "        data.append(img)\n",
    "        labels.append(category)\n",
    "\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "label_as_binary = LabelBinarizer()\n",
    "train__labels = label_as_binary.fit_transform(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained model and add a classifier on top of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x0000028456C62560>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\charl\\anaconda3\\lib\\weakref.py\", line 371, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2)])\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training parameters and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22565 images belonging to 80 classes.\n",
      "Found 6505 images belonging to 80 classes.\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[CategoricalAccuracy()], run_eagerly=True)\n",
    "bs = 30\n",
    "train_dir = './animals-detection-images-dataset/train'\n",
    "test_dir = \"./animals-detection-images-dataset/test\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=bs, class_mode='categorical', target_size=(224, 224))\n",
    "validation_generator = test_datagen.flow_from_directory(test_dir, batch_size=bs, class_mode='categorical', target_size=(224, 224))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (30, 80) and (30, 10) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[0;32m      2\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      3\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m bs,\n\u001b[0;32m      4\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m                     validation_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m bs,\n\u001b[0;32m      6\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\charl\\anaconda3\\lib\\site-packages\\keras\\backend.py:5529\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   5527\u001b[0m target \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(target)\n\u001b[0;32m   5528\u001b[0m output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(output)\n\u001b[1;32m-> 5529\u001b[0m target\u001b[39m.\u001b[39;49mshape\u001b[39m.\u001b[39;49massert_is_compatible_with(output\u001b[39m.\u001b[39;49mshape)\n\u001b[0;32m   5531\u001b[0m output, from_logits \u001b[39m=\u001b[39m _get_logits(\n\u001b[0;32m   5532\u001b[0m     output, from_logits, \u001b[39m\"\u001b[39m\u001b[39mSoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5533\u001b[0m )\n\u001b[0;32m   5534\u001b[0m \u001b[39mif\u001b[39;00m from_logits:\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (30, 80) and (30, 10) are incompatible"
     ]
    }
   ],
   "source": [
    "history = model.train_on_batch(train_datagen, train__labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(test_data)\n",
    "label_pred = np.argmax(label_pred, axis=1)\n",
    "label_true = np.argmax(test_labels, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(label_true, label_pred)\n",
    "precision = precision_score(label_true, label_pred, average='weighted')\n",
    "recall = recall_score(label_true, label_pred, average='weighted')\n",
    "f1 = f1_score(label_true, label_pred, average='weighted')\n",
    "\n",
    "print('Accuracy: {:.2f}%, Precision: {:.2f}%, Recall: {:.2f}%, F1 Score: {:.2f}%'.format(accuracy * 100,\n",
    "                                                                                         precision * 100,\n",
    "                                                                                         recall * 100,\n",
    "                                                                                         f1 * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, 'Animals_prediction_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
